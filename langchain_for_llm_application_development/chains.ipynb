{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e14d3f7d",
   "metadata": {},
   "source": [
    "- LLMChain can be used to take a prompt template, pass it to an llm with input and get a response all in 1 step\n",
    "- Sequential chains run sequence of chains 1 after another. works best when we have chains that expect only one input and return only 1 output\n",
    "Input\n",
    "  |\n",
    "  v\n",
    "+-------------------+\n",
    "|   First Chain     |   (e.g., generates a company name from a product)\n",
    "+-------------------+\n",
    "  |\n",
    "  v\n",
    "+-------------------+\n",
    "|   Second Chain    |   (e.g., writes a description for the company name)\n",
    "+-------------------+\n",
    "  |\n",
    "  v\n",
    "Output\n",
    "- when there are multiple inputs/outputs you can use the regular sequential chain but the whole chain which is a combination of multiple chains has a single input & output.\n",
    "- the important thing here is the naming of inputs & outputs. You need to get the right so that subsequent chains take in the correct input\n",
    "         +-------------------+\n",
    "Inputs:  |  {\"product\": ...,\n",
    "         |   \"country\": ...} |\n",
    "         +-------------------+\n",
    "                   |\n",
    "                   v\n",
    "        +--------------------------+\n",
    "        |      First Chain         |\n",
    "        |  (e.g., uses product &   |\n",
    "        |   country, outputs       |\n",
    "        |   company_name & slogan) |\n",
    "        +--------------------------+\n",
    "                   |\n",
    "                   v\n",
    "        +--------------------------+\n",
    "        |      Second Chain        |\n",
    "        |  (e.g., uses company_name|\n",
    "        |   & slogan, outputs      |\n",
    "        |   description)           |\n",
    "        +--------------------------+\n",
    "                   |\n",
    "                   v\n",
    "         +-------------------+\n",
    "Outputs: | {\"company_name\": ...,\n",
    "         |  \"slogan\": ...,\n",
    "         |  \"description\": ...}\n",
    "         +-------------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934be5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())  # read local .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ef738d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\colgann\\training\\langchain\\langchain_for_llm_application_development\\venv\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\colgann\\training\\langchain\\langchain_for_llm_application_development\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\colgann\\training\\langchain\\langchain_for_llm_application_development\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.1-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 4.0 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.6/11.0 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.4/11.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.5/11.0 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 4.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.6/11.0 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.4/11.0 MB 4.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.0/11.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab81fdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#create sample dataframe\n",
    "data = {\n",
    "    'name': ['nicole', 'karl', 'marion'],\n",
    "    'age': [25, 14, 50],\n",
    "    'city': ['galway', 'athlone', 'london']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dfe555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edb3fd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nicole</td>\n",
       "      <td>25</td>\n",
       "      <td>galway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>karl</td>\n",
       "      <td>14</td>\n",
       "      <td>athlone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marion</td>\n",
       "      <td>50</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  age     city\n",
       "0  nicole   25   galway\n",
       "1    karl   14  athlone\n",
       "2  marion   50   london"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be4791",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1166daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286fd9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colgann\\AppData\\Local\\Temp\\ipykernel_37824\\4147887815.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0.9)\n"
     ]
    }
   ],
   "source": [
    "# Add a little randomness in temp for creativity\n",
    "llm = ChatOpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d749140",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d35b7263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colgann\\AppData\\Local\\Temp\\ipykernel_37824\\2891286404.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm,prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08ecf97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colgann\\AppData\\Local\\Temp\\ipykernel_37824\\818320379.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(product)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"TechTalk\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Phones\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccac3b7",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8012b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94dfdf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# Prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# chain 1\n",
    "first_chain = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7785cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 word description for the following company: {company_name}\"\n",
    ")\n",
    "#chain 2\n",
    "second_chain = LLMChain(llm=llm,prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9da563db",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(\n",
    "    chains=[first_chain, second_chain],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4285aa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"Protein Fusion\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mProtein Fusion creates innovative and delicious protein bars that blend plant-based and whey proteins for the ultimate post-workout snack.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Protein Fusion creates innovative and delicious protein bars that blend plant-based and whey proteins for the ultimate post-workout snack.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(\"protein powder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d727ad7",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b50f8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8d049a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# Prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english\" \\\n",
    "    \"\\n\\n{review}\"\n",
    ")\n",
    "\n",
    "# Chain1: input=review, output=english_review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, output_key=\"english_review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d401ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarise the following review in 1 sentence:\" \\\n",
    "    \"\\n\\n{english_review}\"\n",
    ")\n",
    "#chain2: input=english_review, output=summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, output_key=\"summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1168d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template3: find out the language of the review\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\" \\\n",
    "    \"\\n\\n{review}\"\n",
    ")\n",
    "# Chain3: input=initial review, output=language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt, output_key=\"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11aff353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following\"\n",
    "    \"summary in the specified language\"\n",
    "    \"\\n\\n{summary}\\n\\n{language}\"\n",
    ")\n",
    "#chain4: input=summary,language, output=followup_msg\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt, output_key=\"followup_msg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c12e54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall_chain: input=review, output=english_review, summary, followup_msd\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one,chain_two,chain_three,chain_four],\n",
    "    input_variables=[\"review\"],\n",
    "    output_variables=[\"english_review\", \"summary\", \"followup_msg\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fade459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colgann\\AppData\\Local\\Temp\\ipykernel_37824\\2309184924.py:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  overall_chain(review)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review': 'Ich liebe es!',\n",
       " 'english_review': 'I love it!',\n",
       " 'summary': 'The reviewer has a strong positive feeling towards the product or experience.',\n",
       " 'followup_msg': 'Vielen Dank für Ihr tolles Feedback! Es freut uns sehr zu hören, dass Sie so eine positive Erfahrung mit unserem Produkt / unserer Dienstleistung gemacht haben. Wir sind immer bestrebt, unseren Kunden das Beste zu bieten und es macht uns sehr glücklich zu hören, dass es Ihnen gefallen hat. Wir hoffen, Sie auch in Zukunft weiterhin zufriedenstellen zu können. Vielen Dank nochmals für Ihr Lob!'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"Ich liebe es!\"\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chains 7:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb511b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f1d9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
