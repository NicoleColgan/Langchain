{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f36084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain_community\n",
    "# !pip install python-dotenv\n",
    "#! pip install langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd678768",
   "metadata": {},
   "source": [
    "The line _ = load_dotenv(find_dotenv()) is a two-step process. First, find_dotenv() searches for a file named .env by looking in the current directory and then moving up through parent directories until it finds the file. This is useful in projects where the .env file might not be in the same directory as your script. Once the path to the .env file is found, load_dotenv() reads the file and loads any environment variables defined within it into the system environment. This allows sensitive information, like API keys, to be kept out of your source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e0fdbea-f17d-4fa5-96a3-28d0b197f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # Load environment variables from .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba378cbe",
   "metadata": {},
   "source": [
    "Interace with OpenAI's API to get a completion for a given prompt\n",
    "\n",
    "In the new OpenAI Python library (v1.0.0 and above), a client is an object you create to manage your connection and authentication with the OpenAI API.\n",
    "The client handles your API key, manages requests, and provides methods (like client.chat.completions.create) to interact with the API.\n",
    "\n",
    "\"user\": Represents input from the human interacting with the assistant.\n",
    "\"assistant\": Represents responses from the AI model.\n",
    "\"system\": (optional) Used to set behavior or context for the assistant.\n",
    "By specifying \"role\": \"user\", you ensure the model treats the message as a prompt it should respond to, rather than as its own previous output or system instructions. This helps the model generate relevant and accurate responses.\n",
    "\n",
    "Lower temperature (e.g., 0–0.3): More fact-oriented, focused, and deterministic responses. Good for tasks needing accuracy and consistency.\n",
    "Higher temperature (e.g., 0.7–1): More creative, varied, and open-ended responses. Useful for brainstorming, storytelling, or generating ideas.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee13596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    client = openai.Client()    # create a client instance\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60d1646b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 + 1 equals 2.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"what is 1 + 1?\")  # Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe7d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"Betreff: Anfrage\n",
    "\n",
    "Sehr geehrte Damen und Herren,\n",
    "\n",
    "ich hoffe, es geht Ihnen gut. Ich möchte mich erkundigen, ob Sie mir bitte weitere Informationen zu Ihrem Angebot zusenden könnten.\n",
    "\n",
    "Vielen Dank im Voraus für Ihre Unterstützung.\n",
    "\n",
    "Mit freundlichen Grüßen\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b29c611",
   "metadata": {},
   "source": [
    "translate in this style - use this style in you answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f42d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"Irish English\\n\n",
    "    in a calm and professional tone\" \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98b00df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following email \n",
      "\n",
      "that is delimited by triple backticks into a styke that is Irish English\n",
      "\n",
      "    in a calm and professional tone\" \n",
      "    .\n",
      "text: ```Betreff: Anfrage\n",
      "\n",
      "Sehr geehrte Damen und Herren,\n",
      "\n",
      "ich hoffe, es geht Ihnen gut. Ich möchte mich erkundigen, ob Sie mir bitte weitere Informationen zu Ihrem Angebot zusenden könnten.\n",
      "\n",
      "Vielen Dank im Voraus für Ihre Unterstützung.\n",
      "\n",
      "Mit freundlichen Grüßen```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the following email \\n\n",
    "that is delimited by triple backticks into a styke that is {style}.\n",
    "text: ```{customer_email}```\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f15229c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Inquiry\n",
      "\n",
      "Dear Ladies and Gentlemen,\n",
      "\n",
      "I hope you're keeping well. I'd like to inquire if you could please send me more information about your offer.\n",
      "\n",
      "Thank you in advance for your assistance.\n",
      "\n",
      "Kind regards\n"
     ]
    }
   ],
   "source": [
    "rsponse = get_completion(prompt)\n",
    "print(rsponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f3929",
   "metadata": {},
   "source": [
    "imagine having to do this with loads of mails/languages. \n",
    "lets find a more convienient way to do this with langchain\n",
    "\n",
    "Chatopenai is langchains abstraction for chatgpt api\n",
    "use it as a wrapper for openai llm\n",
    "This class inherits from BaseChatModel and is designed to make it easy to interact with OpenAI's chat APIs, such as GPT-3.5-turbo or GPT-4, by handling configuration, authentication, and API calls in a user-friendly and extensible way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76b7e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf2323",
   "metadata": {},
   "source": [
    "default temperature is 0.7 so for more accurate response, set it yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30cef488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colgann\\AppData\\Local\\Temp\\ipykernel_26024\\4275512504.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(temperature=0.0)  # Set temperature to 0 for deterministic output\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(temperature=0.0)  # Set temperature to 0 for deterministic output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d192c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"\n",
    "Translate the following email\n",
    "that is delimited by triple backticks into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fbef4b",
   "metadata": {},
   "source": [
    "To repeatedly use this template, import langchain ChatPromptTemplate\n",
    "\n",
    "Notice how we didnt use the formatted string. Prompt templates are better for more complex, longer prompts\n",
    "When you print the prompt template u can see it picks up the variables \n",
    "\n",
    "langchain provides prompty for common operations like smmarisation or question-answering, connecting to sql dbs, connecting to apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f37b5a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3af5dfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['customer_email', 'style'] input_types={} partial_variables={} template='\\nTranslate the following email\\nthat is delimited by triple backticks into a style that is {style}.\\ntext: ```{customer_email}```\\n'\n",
      "['customer_email', 'style']\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.messages[0].prompt)\n",
    "print(prompt_template.messages[0].prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ae89300",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"\"\"Irish English\n",
    "    in a calm and professional tone\" \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59241ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"Betreff: Anfrage\n",
    "Sehr geehrte Damen und Herren,\n",
    "ich hoffe, es geht Ihnen gut. Ich möchte mich erkundigen, ob Sie mir bitte weitere Informationen zu Ihrem Angebot zusenden könnten.\n",
    "Vielen Dank im Voraus für Ihre Unterstützung.\n",
    "\n",
    "Mit freundlichen Grüßen\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813307c1",
   "metadata": {},
   "source": [
    "Generate prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92609779",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "    style=customer_style,\n",
    "    customer_email=customer_email\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99e54532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ea14d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\\nTranslate the following email\\nthat is delimited by triple backticks into a style that is Irish English\\n    in a calm and professional tone\" \\n    .\\ntext: ```Betreff: Anfrage\\nSehr geehrte Damen und Herren,\\nich hoffe, es geht Ihnen gut. Ich möchte mich erkundigen, ob Sie mir bitte weitere Informationen zu Ihrem Angebot zusenden könnten.\\nVielen Dank im Voraus für Ihre Unterstützung.\\n\\nMit freundlichen Grüßen```\\n' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2171c",
   "metadata": {},
   "source": [
    "Pass this prompt to the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ead94dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\colgann\\AppData\\Local\\Temp\\ipykernel_17472\\3043644737.py:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  customer_rsponse = chat(customer_messages)\n"
     ]
    }
   ],
   "source": [
    "customer_rsponse = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cc66db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Inquiry\n",
      "\n",
      "Dear Sir/Madam,\n",
      "\n",
      "I hope you are keeping well. I would like to inquire if you could please send me further information about your offer.\n",
      "\n",
      "Thank you in advance for your assistance.\n",
      "\n",
      "Kind regards\n"
     ]
    }
   ],
   "source": [
    "print(customer_rsponse.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9986d4a2",
   "metadata": {},
   "source": [
    "We can now use this prompt template again & again with different params (style & email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b61e52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there, I hope you're doing well. Thank you for reaching out to us. We appreciate your interest in our services. I will be happy to provide you with more information about our offerings. Please give me a moment to gather the details, and I will get back to you shortly. Thank you for your patience!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fc20ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_style_jamaican = \"Jamaican English\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f25452f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"\\nTranslate the following email\\nthat is delimited by triple backticks into a style that is Jamaican English.\\ntext: ```Hey there, I hope you're doing well. Thank you for reaching out to us. We appreciate your interest in our services. I will be happy to provide you with more information about our offerings. Please give me a moment to gather the details, and I will get back to you shortly. Thank you for your patience!```\\n\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "customer_messages_2 = prompt_template.format_messages(\n",
    "    style=service_style_jamaican,\n",
    "    customer_email=service_reply\n",
    ")\n",
    "print(customer_messages_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "189d0381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey deh, mi hope yuh good. Big up fi linkin' wi. Wi appreciate yuh interest inna wi services. Mi gwine happy fi give yuh more info 'bout weh wi have fi offer. Jus' gi mi a likkle time fi gather di details, an' mi gwine get back to yuh soon. Tank yuh fi yuh patience!\n"
     ]
    }
   ],
   "source": [
    "customer_rsponse_2 = chat(customer_messages_2)\n",
    "print(customer_rsponse_2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de4a51",
   "metadata": {},
   "source": [
    "# Parsing\n",
    "How to extract info & output json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c8dd9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'affordable'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Python dictionary\n",
    "{\n",
    "    \"gift\": False,\n",
    "    \"delivery_days\": 5,\n",
    "    \"price_value\": \"affordable\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e651646",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing. It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d91d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template = \"\"\"\\\n",
    "for the folwing text, etract the following information:\n",
    "\n",
    "gift: if the item was purchased as a gif for someone else? ans\n",
    "delivery_days: how many days did it take to deliver the item\n",
    "price_value: extract any sentences aboutthe price or value\n",
    "\n",
    "format the output as json with the following keys:\n",
    "\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab92e581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"gift\": \"yes\",\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt_template2 = ChatPromptTemplate.from_template(review_template)\n",
    "messages = prompt_template2.format_messages(text=customer_review)\n",
    "chat=ChatOpenAI(temperature=0.0)\n",
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043417ec",
   "metadata": {},
   "source": [
    "Use Langchain parser to extract json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "032bff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dece914",
   "metadata": {},
   "source": [
    "Tell it what you want it to parse with schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "406f6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\", description=\"was this item a gift? Answer 'True' if it was, 'False' if it was not, and 'unknown' if you dont know\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\", description=\"how many days did it take to deliver the item. Answer 1 for one day, 2 for two days etc., or unknown if you dont know\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\", description=\"extract any info aout the price value then output them as csv values\")\n",
    "\n",
    "responseSchemas = [gift_schema, delivery_days_schema, price_value_schema]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9750f",
   "metadata": {},
   "source": [
    "Langchain can give you the format instructions to format the output eg. as JSON\n",
    "\n",
    "You can then include that in your template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b1f42ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser(response_schemas=responseSchemas)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3477f727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // was this item a gift? Answer 'True' if it was, 'False' if it was not, and 'unknown' if you dont know\n",
      "\t\"delivery_days\": string  // how many days did it take to deliver the item. Answer 1 for one day, 2 for two days etc., or unknown if you dont know\n",
      "\t\"price_value\": string  // extract any info aout the price value then output them as csv values\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94cc6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template2 = \"\"\"\\\n",
    "for the folwing text, etract the following information:\n",
    "\n",
    "gift: if the item was purchased as a gif for someone else? ans\n",
    "delivery_days: how many days did it take to deliver the item\n",
    "price_value: extract any sentences aboutthe price or value\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02a9b0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": \"True\",\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(review_template2)\n",
    "messages = prompt_template.format_messages(\n",
    "    text=customer_review,\n",
    "    format_instructions=format_instructions\n",
    "    )\n",
    "chat=ChatOpenAI(temperature=0.0)\n",
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "16:00 models,pr..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
